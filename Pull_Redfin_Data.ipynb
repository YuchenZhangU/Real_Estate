{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webdriver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price by zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.zip-codes.com/state/tx.asp'\n",
    "soup = webdriver.get_soup(url, driver_type='selenium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.select('table.statTable>tbody>tr>td:nth-of-type(2)>a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.select('table.statTable>tbody>tr>td:first-of-type>a')\n",
    "zipcode_tx = [link.text.split()[-1] for link in links]\n",
    "links = soup.select('table.statTable>tbody>tr>td:nth-of-type(2)>a')\n",
    "city_tx = [link.text.split()[-1] for link in links]\n",
    "links = soup.select('table.statTable>tbody>tr>td:nth-of-type(3)>a')\n",
    "county_tx = [link.text.split()[-1] for link in links]\n",
    "links = soup.select('table.statTable>tbody>tr>td:nth-of-type(4)')\n",
    "ziptype = [link.text.split()[-1] for link in links]\n",
    "ziptype =  ziptype[1:]\n",
    "dic_data = {'zipcode': zipcode_tx, 'city': city_tx, 'county': county_tx, 'ziptype': ziptype}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zip = pd.DataFrame(dic_data, columns=['zipcode', 'city', 'county', 'ziptype'])\n",
    "df_zip.to_csv('./data/zipcode_tx.csv', index=False)\n",
    "df_zip.ziptype.unique()\n",
    "df_zip = df_zip[df_zip.ziptype=='Standard']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redfin data by zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "hou_counties = ['Harris', 'Bend', 'Montgomery', 'Walker']\n",
    "df_zip_hou = df_zip[df_zip.county.isin(hou_counties)]\n",
    "df_zip_hou.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mywebdriver\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from random import random\n",
    "import traceback\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "zipcode = '77007'\n",
    "url_redfin = f'https://www.redfin.com/zipcode/{zipcode}/housing-market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchenzhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: use options instead of chrome_options\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--window-size=2400,1080\")\n",
    "chrome_options.add_argument(\"--silent\") # open without popup\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.get(url_redfin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_css_selector('div[data-react-server-root-id=\"19\"] .ModeToggler.graphTabs button:first-of-type').click()\n",
    "svg = driver.find_element_by_css_selector('div[data-react-server-root-id=\"19\"] .lineGraph .VictoryContainer>svg')\n",
    "svg = svg.get_attribute('outerHTML')\n",
    "svg = svg.replace('svg width', 'svg xmlns=\"http://www.w3.org/2000/svg\" width')\n",
    "with open(f'image/{zipcode}_1y.svg', 'w') as f:\n",
    "    f.write(svg)\n",
    "driver.find_element_by_css_selector('div[data-react-server-root-id=\"19\"] .ModeToggler.graphTabs button:nth-of-type(3)').click()\n",
    "svg3 = driver.find_element_by_css_selector('div[data-react-server-root-id=\"19\"] .lineGraph .VictoryContainer>svg')\n",
    "svg3 = svg3.get_attribute('outerHTML')\n",
    "svg3 = svg3.replace('svg width', 'svg xmlns=\"http://www.w3.org/2000/svg\" width')\n",
    "with open(f'image/{zipcode}_3y.svg', 'w') as f:\n",
    "    f.write(svg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- There are 5 errors ----\n",
      "---- There are 10 errors ----\n",
      "---- There are 15 errors ----\n",
      "---- There are 20 errors ----\n"
     ]
    }
   ],
   "source": [
    "ls_zipdata = []\n",
    "ls_err = []\n",
    "sec_sleep = 20\n",
    "for i, row in df_zip_hou.iterrows():\n",
    "    # initial zip code \n",
    "    zipcode = row['zipcode']\n",
    "    url_redfin = f'https://www.redfin.com/zipcode/{zipcode}/housing-market'\n",
    "    try:\n",
    "        # load web\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "        chrome_options.add_argument(\"--silent\") # open without popup\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url_redfin)\n",
    "        # get price trend svg\n",
    "        driver.find_element_by_css_selector('div[data-react-server-root-id=\"19\"] .ModeToggler.graphTabs button:first-of-type').click()\n",
    "        svg = driver.find_element_by_css_selector('div[data-react-server-root-id=\"19\"] .lineGraph .VictoryContainer>svg')\n",
    "        svg = svg.get_attribute('outerHTML')\n",
    "        svg = svg.replace('svg width', 'svg xmlns=\"http://www.w3.org/2000/svg\" width')\n",
    "        with open(f'image/{zipcode}_1y.svg', 'w') as f:\n",
    "            f.write(svg)\n",
    "        driver.find_element_by_css_selector('div[data-react-server-root-id=\"19\"] .ModeToggler.graphTabs button:nth-of-type(3)').click()\n",
    "        svg3 = driver.find_element_by_css_selector('div[data-react-server-root-id=\"19\"] .lineGraph .VictoryContainer>svg')\n",
    "        svg3 = svg3.get_attribute('outerHTML')\n",
    "        svg3 = svg3.replace('svg width', 'svg xmlns=\"http://www.w3.org/2000/svg\" width')\n",
    "        with open(f'image/{zipcode}_3y.svg', 'w') as f:\n",
    "            f.write(svg3)\n",
    "\n",
    "        # load market insight # soup_zip = mywebdriver.get_soup(url_redfin, driver_type='selenium')\n",
    "        soup_zip = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        driver.quit()\n",
    "        # median price, # of home sold, median DOM, score, \n",
    "        soup_price = soup_zip.select('.MarketInsightsGraphSection:first-of-type button:first-of-type')[0]\n",
    "        soup_sold = soup_zip.select('.MarketInsightsGraphSection:first-of-type button:nth-of-type(2)')[0]\n",
    "        soup_DOM = soup_zip.select('.MarketInsightsGraphSection:first-of-type button:nth-of-type(3)')[0]\n",
    "        median_price = float(soup_price.select('.dataPoints>.value')[0].text.replace('$','').replace(',',''))\n",
    "        median_price_yoy = float(soup_price.select('.dataPoints>.yoyChange')[0].text.replace('+','').replace('%','').replace(' year-over-year', ''))\n",
    "        n_sold = float(soup_sold.select('.dataPoints>.value')[0].text.replace('$','').replace(',',''))\n",
    "        n_sold_yoy = float(soup_sold.select('.dataPoints>.yoyChange')[0].text.replace('+','').replace('%','').replace(' year-over-year', ''))\n",
    "        DOM = float(soup_DOM.select('.dataPoints>.value')[0].text.replace('$','').replace(',',''))\n",
    "        DOM_yoy = float(soup_DOM.select('.dataPoints>.yoyChange')[0].text.replace('+','').replace('%','').replace(' year-over-year', ''))\n",
    "        score = int(soup_zip.select('.scoreTM>.score')[0].text)\n",
    "        dic_zipdata = {'zipcode': zipcode, 'url': url_redfin, 'median_price': median_price, 'median_price_yoy': median_price_yoy, 'n_sold': n_sold, 'n_sold_yoy': n_sold_yoy, 'DOM': DOM, 'DOM_yoy': DOM_yoy, 'redfin_score': score}\n",
    "        ls_zipdata.append(dic_zipdata)\n",
    "    except:\n",
    "        ls_err.append({'zipcode': zipcode, 'url': url_redfin, 'err': traceback.format_exc()})\n",
    "        if len(ls_err) % 5 == 0:\n",
    "            print(f'---- There are {len(ls_err)} errors ----')\n",
    "    time.sleep(random() * sec_sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>url</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77010</td>\n",
       "      <td>https://www.redfin.com/zipcode/77010/housing-m...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"&lt;i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77011</td>\n",
       "      <td>https://www.redfin.com/zipcode/77011/housing-m...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"&lt;i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77012</td>\n",
       "      <td>https://www.redfin.com/zipcode/77012/housing-m...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"&lt;i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77013</td>\n",
       "      <td>https://www.redfin.com/zipcode/77013/housing-m...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"&lt;i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77025</td>\n",
       "      <td>https://www.redfin.com/zipcode/77025/housing-m...</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"&lt;i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zipcode                                                url  \\\n",
       "0   77010  https://www.redfin.com/zipcode/77010/housing-m...   \n",
       "1   77011  https://www.redfin.com/zipcode/77011/housing-m...   \n",
       "2   77012  https://www.redfin.com/zipcode/77012/housing-m...   \n",
       "3   77013  https://www.redfin.com/zipcode/77013/housing-m...   \n",
       "4   77025  https://www.redfin.com/zipcode/77025/housing-m...   \n",
       "\n",
       "                                                 err  \n",
       "0  Traceback (most recent call last):\\n  File \"<i...  \n",
       "1  Traceback (most recent call last):\\n  File \"<i...  \n",
       "2  Traceback (most recent call last):\\n  File \"<i...  \n",
       "3  Traceback (most recent call last):\\n  File \"<i...  \n",
       "4  Traceback (most recent call last):\\n  File \"<i...  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze error\n",
    "df_err = pd.DataFrame(ls_err)\n",
    "df_err = df_err[['zipcode', 'url', 'err']]\n",
    "df_err.to_csv('./data/zipcode_data_err.csv', index=False)\n",
    "df_err.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check error\n",
    "len(ls_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 9)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# form dataframe\n",
    "df_zipdata = pd.DataFrame(ls_zipdata)\n",
    "df_zipdata = df_zipdata[['zipcode', 'url', 'median_price', 'median_price_yoy', 'n_sold', 'n_sold_yoy', 'DOM', 'DOM_yoy', 'redfin_score']]\n",
    "df_zipdata['median_price_yoy'] = df_zipdata['median_price_yoy']/100\n",
    "df_zipdata['n_sold_yoy'] = df_zipdata['n_sold_yoy']/100\n",
    "df_zipdata['DOM_yoy'] = df_zipdata['DOM_yoy']/100\n",
    "df_zipdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image path\n",
    "def get_image_path(x):\n",
    "    return f'./image/{x}_1y.svg'\n",
    "def get_image_path3(x):\n",
    "    return f'./image/{x}_3y.svg'\n",
    "df_zipdata['svg1'] = df_zipdata.zipcode.map(get_image_path)\n",
    "df_zipdata['svg3'] = df_zipdata.zipcode.map(get_image_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv\n",
    "df_zipdata.to_csv('./data/zipcode_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
